{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant\n",
      "benign\n"
     ]
    }
   ],
   "source": [
    "SIZE = 64\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for directory_path in glob.glob(\"train/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.jpg\")):\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img,(SIZE,SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malignant\n",
      "benign\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for directory_path in glob.glob(\"test/*\"):\n",
    "    label = directory_path.split(\"/\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path,\"*.jpg\")):\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img,(SIZE,SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_images).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "# trocar o nome das variáveis\n",
    "train_images = np.array(train_images)\n",
    "test_images = np.array(test_images)\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "\n",
    "\n",
    "# Normalizar\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Definição dos modelo\n",
    "#Load model wothout classifier/fully connected layers\n",
    "VGG_model = VGG16(include_top=False, weights='imagenet', input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 98s 448ms/step\n",
      "(7000, 2, 2, 512)\n",
      "[[[0.01645227 0.         0.33360118 ... 0.         1.1429665  0.        ]\n",
      "  [0.34460384 0.         0.403619   ... 0.         0.78148204 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         1.1382532  0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.91165644 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "out_vgg = VGG_model.predict(x_train)\n",
    "\n",
    "print(out_vgg.shape)\n",
    "print(out_vgg[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4096)              8392704   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12597250 (48.05 MB)\n",
      "Trainable params: 12597250 (48.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "DNN_model = Sequential()\n",
    "DNN_model.add(Dense(2048,activation=\"relu\",input_shape=(2048, )))\n",
    "DNN_model.add(Dense(4096,activation=\"relu\"))\n",
    "DNN_model.add(Dense(2,activation=\"sigmoid\"))\n",
    "\n",
    "DNN_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(DNN_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 - 32s - loss: 0.2088 - accuracy: 0.9159 - 32s/epoch - 147ms/step\n",
      "Epoch 2/10\n",
      "219/219 - 32s - loss: 0.1763 - accuracy: 0.9311 - 32s/epoch - 145ms/step\n",
      "Epoch 3/10\n",
      "219/219 - 32s - loss: 0.1630 - accuracy: 0.9359 - 32s/epoch - 147ms/step\n",
      "Epoch 4/10\n",
      "219/219 - 32s - loss: 0.1483 - accuracy: 0.9420 - 32s/epoch - 146ms/step\n",
      "Epoch 5/10\n",
      "219/219 - 32s - loss: 0.1276 - accuracy: 0.9491 - 32s/epoch - 146ms/step\n",
      "Epoch 6/10\n",
      "219/219 - 32s - loss: 0.1215 - accuracy: 0.9513 - 32s/epoch - 147ms/step\n",
      "Epoch 7/10\n",
      "219/219 - 32s - loss: 0.1030 - accuracy: 0.9619 - 32s/epoch - 146ms/step\n",
      "Epoch 8/10\n",
      "219/219 - 32s - loss: 0.1011 - accuracy: 0.9584 - 32s/epoch - 147ms/step\n",
      "Epoch 9/10\n",
      "219/219 - 32s - loss: 0.0894 - accuracy: 0.9670 - 32s/epoch - 147ms/step\n",
      "Epoch 10/10\n",
      "219/219 - 34s - loss: 0.0796 - accuracy: 0.9701 - 34s/epoch - 156ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x71bb9a6b4e50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_vgg = np.array([x.flatten() for x in out_vgg])\n",
    "\n",
    "DNN_model.fit(out_vgg,y_train_one_hot, epochs=10, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 41s 440ms/step\n",
      "94/94 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_imgs = VGG_model.predict(x_test)\n",
    "\n",
    "predict_imgs = np.array([x.flatten() for x in predict_imgs])\n",
    "\n",
    "preditc_out = DNN_model.predict(predict_imgs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(preditc_out)):\n",
    "    preditc_out[i][0] = 1 if preditc_out[i][0] > 0.5 else 0\n",
    "    preditc_out[i][1] = 1 if preditc_out[i][1] > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1361  302]\n",
      " [ 139 1198]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = np.array([[0,0],[0,0]])\n",
    "\n",
    "for i in range(0,len(preditc_out)):\n",
    "    if preditc_out[i][0] == 1:\n",
    "        if y_test_one_hot[i][0]:\n",
    "            conf_mat[0][0] += 1\n",
    "        else:\n",
    "            conf_mat[0][1] += 1\n",
    "    else:\n",
    "        if y_test_one_hot[i][0]:\n",
    "            conf_mat[1][0] += 1\n",
    "        else:\n",
    "            conf_mat[1][1] += 1\n",
    "\n",
    "print(conf_mat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
